{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "import time\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "# from openal import *\n",
    "import random\n",
    "import threading\n",
    "\n",
    "import threading\n",
    "from threading import Condition\n",
    "import time\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTES\n",
    "WEIGHTS = '../YOLO v3/yolov3.weights'\n",
    "CONFIG = '../YOLO v3/yolov3.cfg'\n",
    "CLASES = '../YOLO TINY/yolov3-tiny.txt'\n",
    "MAX_DISTANCIA_CM = 500 #5 metros\n",
    "MAX_ANGLE_LENSE = 85 #En grados\n",
    "W=768\n",
    "H=576"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = None\n",
    "# with open(CLASES, 'r') as f:\n",
    "#      classes = [line.strip() for line in f.readlines()]\n",
    "# net = cv2.dnn.readNet(WEIGHTS, CONFIG)\n",
    "        \n",
    "# def get_output_layers(net):\n",
    "    \n",
    "#     layer_names = net.getLayerNames()\n",
    "    \n",
    "#     output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "#     return output_layers\n",
    "\n",
    "\n",
    "# def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h, color):\n",
    "\n",
    "#     label = str(classes[class_id]) \n",
    "\n",
    "#     cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "\n",
    "#     cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    \n",
    "# def detect_objects(orig_image_paths, net):\n",
    "#     orig_images = [cv2.imread(i) for i in orig_image_paths]\n",
    "#     images = [cv2.resize(i, (768, 576)) for i in orig_images]\n",
    "    \n",
    "#     Width = images[0].shape[1]\n",
    "#     Height = images[0].shape[0]\n",
    "#     scale = 0.00392\n",
    "#     resultado_final=[]\n",
    "\n",
    "#     for image in images:\n",
    "#         resultado=[]\n",
    "#         color=np.random.uniform(0, 255, 3)\n",
    "        \n",
    "#         blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "#         net.setInput(blob)\n",
    "#         outs = net.forward(get_output_layers(net))\n",
    "\n",
    "#         class_ids = []\n",
    "#         confidences = []\n",
    "#         boxes = []\n",
    "#         conf_threshold = 0.5\n",
    "#         nms_threshold = 0.4\n",
    "\n",
    "#         for out in outs:\n",
    "#             for detection in out:\n",
    "#                 scores = detection[5:]\n",
    "#                 class_id = np.argmax(scores)\n",
    "#                 confidence = scores[class_id]\n",
    "#                 if confidence > 0.5:\n",
    "#                     center_x = int(detection[0] * Width)\n",
    "#                     center_y = int(detection[1] * Height)\n",
    "#                     w = int(detection[2] * Width)\n",
    "#                     h = int(detection[3] * Height)\n",
    "#                     x = center_x - w / 2\n",
    "#                     y = center_y - h / 2\n",
    "#                     class_ids.append(class_id)\n",
    "#                     confidences.append(float(confidence))\n",
    "#                     boxes.append([x, y, w, h])\n",
    "\n",
    "    \n",
    "#         indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "        \n",
    "#         for i in indices:\n",
    "#             i = i[0]\n",
    "#             box = boxes[i]\n",
    "#             x = box[0]\n",
    "#             y = box[1]\n",
    "#             w = box[2]\n",
    "#             h = box[3]\n",
    "#             draw_prediction(images[0], class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h), color)\n",
    "#             resultado.append({\"class\": classes[class_ids[i]], \"confidence\": confidences[i], \"coordinates\":box})\n",
    "#         resultado_final.append(resultado)\n",
    "# #         cv2.imshow(\"object detection\", image)\n",
    "# #         cv2.waitKey()\n",
    "# #         cv2.destroyAllWindows()\n",
    "#     return resultado_final,images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "net = cv2.dnn.readNetFromCaffe(\"../MobileNet SSD + DNN/MobileNetSSD_deploy.prototxt.txt\", \"../MobileNet SSD + DNN/MobileNetSSD_deploy.caffemodel\") \n",
    "\n",
    "def detect_objects(orig_image_paths, net):\n",
    "    orig_images = [cv2.imread(i) for i in orig_image_paths]\n",
    "    images = [cv2.resize(i, (W, H)) for i in orig_images]\n",
    "    \n",
    "    w = images[0].shape[1]\n",
    "    h = images[0].shape[0]\n",
    "    resultado_final=[]\n",
    "    \n",
    "    for image in images:\n",
    "        resultado=[]\n",
    "        COLORS=np.random.uniform(0, 255, 3)\n",
    "        \n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "\n",
    "        for i in np.arange(0, detections.shape[2]):\n",
    "            # extract the confidence (i.e., probability) associated with the prediction\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            \n",
    "            # filter out weak detections by ensuring the `confidence` is greater than the minimum confidence\n",
    "            if confidence > 0.2:\n",
    "                # extract the index of the class label from the `detections`, then compute the (x, y)-coordinates\n",
    "                # of the bounding box for the object\n",
    "                idx = int(detections[0, 0, i, 1])\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                \n",
    "                # display the prediction\n",
    "                label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "                #print(\"[INFO] {}\".format(label))\n",
    "                cv2.rectangle(images[0], (startX, startY), (endX, endY), COLORS, 2)\n",
    "                y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "                cv2.putText(images[0], label, (startX, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS, 2)\n",
    "                resultado.append({\"class\": CLASSES[idx], \"confidence\": confidence * 100, \"coordinates\":box})\n",
    "        resultado_final.append(resultado)\n",
    "    return resultado_final,images[0]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIND DISTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_match(left_boxes, right_boxes):\n",
    "    camera_offset_cm=5\n",
    "    # offset_adjust: SSD uses around 4300 and YOLO v3 uses around 30\n",
    "    offset_adjust = 4300\n",
    "    objects=[]\n",
    "\n",
    "    for box1 in left_boxes:\n",
    "        for box2 in right_boxes:\n",
    "            if box1['class']==box2['class']:\n",
    "                c1=[(box1['coordinates'][0]+box1['coordinates'][2]/2),(box1['coordinates'][1]+box1['coordinates'][3]/2)]\n",
    "                c2=[(box2['coordinates'][0]+box2['coordinates'][2]/2),(box2['coordinates'][1]+box2['coordinates'][3]/2)]\n",
    "                sqr_diff=math.sqrt((c1[0]-c2[0])*(c1[0]-c2[0]) + (c1[1]-c2[1])*(c1[1]-c2[1]))\n",
    "#                 print(box1['class']+': '+str(sqr_diff))\n",
    "                x=(c1[0]+c2[0])/2\n",
    "                y=(c1[1]+c2[1])/2\n",
    "                distance=camera_offset_cm/sqr_diff*offset_adjust\n",
    "                if distance <= MAX_DISTANCIA_CM:\n",
    "                    center = [x,y]\n",
    "                    angles = to_polar_coords(center)\n",
    "                    objects.append({\"class\":box1[\"class\"], \"angles\": angles,\n",
    "                                    \"distance\": distance})\n",
    "                    #print([x,y])\n",
    "                    #print([W/2+math.sin(angles[0]),])\n",
    "    return objects\n",
    "\n",
    "def to_polar_coords(center):\n",
    "    im_center=[W/2, H/2]\n",
    "    angulo_x = math.asin(((center[0]-im_center[0])*math.sin(MAX_ANGLE_LENSE))/im_center[0])\n",
    "    angulo_y = math.asin(((center[1]-im_center[1])*math.sin(MAX_ANGLE_LENSE))/im_center[1])\n",
    "    return [angulo_x, angulo_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parcial Time: 0.9706845283508301\n",
      "[{'class': 'chair', 'angles': [0.01028909882095625, -0.11722759477500647], 'distance': 327.82994240082354}, {'class': 'pottedplant', 'angles': [-0.12204361606886074, -0.03027791346353495], 'distance': 411.0477902014902}]\n",
      "Total Time: 0.9726862907409668\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# coordinates, imagen=detect_objects([\"./left.jpeg\", \"./right.jpeg\"], net)\n",
    "\n",
    "# parcial_time = time.time() - start_time\n",
    "# print(\"Parcial Time: \"+str(parcial_time))\n",
    "\n",
    "# objects = stereo_match(coordinates[0], coordinates[1])\n",
    "# print(objects)\n",
    "\n",
    "# elapsed_time = time.time() - start_time\n",
    "# print(\"Total Time: \"+str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class threadSound (threading.Thread):\n",
    "    def __init__(self, x, y, z):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "    def run(self):\n",
    "        playSound(self.x,self.y,self.z)\n",
    "        \n",
    "def beepBeep(source):\n",
    "    source.play()\n",
    "    time.sleep(0.1)\n",
    "    source.stop()\n",
    "    time.sleep(0.05)\n",
    "    source.play()\n",
    "    time.sleep(0.1)\n",
    "    source.stop()\n",
    "    \n",
    "def gradualBeep(source):\n",
    "    source.play()\n",
    "    gain = 15.0\n",
    "    \n",
    "    while gain > 0.02:\n",
    "        source.set_gain(gain)\n",
    "        gain = gain - (gain/1.6)\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    source.set_gain(0.0)\n",
    "    time.sleep(0.5)\n",
    "    source.stop()\n",
    "    \n",
    "def playSound(x,y,z):\n",
    "    v = (0,0,0)\n",
    "    listener = oalGetListener()\n",
    "    listener.set_position(v)\n",
    "    \n",
    "    waveFile = WaveFile(\"agudo5s.wav\")\n",
    "    buffer = Buffer(waveFile)\n",
    "\n",
    "    source = Source(buffer)\n",
    "    source.set_source_relative(True)\n",
    "    v1 = (x,y,z)\n",
    "    source.set_position(v1)\n",
    "#     source.set_looping(True)\n",
    "    pitch = random.random() + 0.3\n",
    "    source.set_pitch(pitch)\n",
    "\n",
    "#     beepBeep(source)\n",
    "    gradualBeep(source)\n",
    "    \n",
    "#     oalQuit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corriendo deteccion\n",
      "corriendo notificacion\n",
      "1.2358782291412354\n",
      "Detected\n",
      "Notify\n",
      "Notify\n",
      "0.610436201095581\n",
      "Detected\n",
      "Notify\n",
      "1.087775468826294\n",
      "Detected\n",
      "Notify\n",
      "Notify\n",
      "0.7515332698822021\n",
      "Detected\n",
      "Notify\n",
      "0.7525355815887451\n",
      "Detected\n",
      "Notify\n",
      "0.5874152183532715\n",
      "Detected\n",
      "Notify\n",
      "0.7175126075744629\n",
      "Detected\n",
      "Notify\n",
      "0.5984232425689697\n",
      "Detected\n",
      "Notify\n",
      "0.5043580532073975\n",
      "Detected\n",
      "Notify\n",
      "0.6024258136749268\n",
      "Detected\n",
      "Notify\n",
      "0.5313770771026611\n",
      "Detected\n",
      "Notify\n",
      "0.3932771682739258\n",
      "Detected\n",
      "Notify\n",
      "0.390277624130249\n",
      "Detected\n",
      "Notify\n",
      "0.5063610076904297\n",
      "Detected\n",
      "Notify\n",
      "0.3642549514770508\n",
      "Detected\n",
      "Notify\n",
      "0.335237979888916\n",
      "Detected\n",
      "Notify\n",
      "[*] all threads finished\n"
     ]
    }
   ],
   "source": [
    "def hilo(i, sem):\n",
    "    if i==1:\n",
    "        correr_deteccion(sem)\n",
    "    else:\n",
    "        correr_notificacion(sem)\n",
    "\n",
    "def correr_deteccion(sem):\n",
    "    print(\"corriendo deteccion\")\n",
    "    while ((time.time() - start_time)<10):         \n",
    "        with sem:\n",
    "            sem.notifyAll()\n",
    "            sem.wait(2)\n",
    "            initial=time.time()\n",
    "            coordinates, imagen=detect_objects([\"./left.jpeg\", \"./right.jpeg\"], net)\n",
    "            objects = stereo_match(coordinates[0], coordinates[1])\n",
    "            print(time.time()-initial)\n",
    "            print(\"Detected\")\n",
    "            \n",
    "    \n",
    "def correr_notificacion(sem):\n",
    "    print(\"corriendo notificacion\")\n",
    "    while ((time.time() - start_time)<10):\n",
    "        with sem:\n",
    "            sem.notifyAll()\n",
    "            sem.wait(1)\n",
    "            print(\"Notify\")\n",
    "#             playSound(2, 100, 2)\n",
    "\n",
    "NTHREADS=2\n",
    "sem=Condition()\n",
    "start_time = time.time()\n",
    "simplethread=[]\n",
    "for i in range(NTHREADS):\n",
    "    # arranque y comienzo de hilo num i+1\n",
    "    simplethread.append(threading.Thread(target=hilo, args=[i+1, sem]))\n",
    "    simplethread[-1].start()\n",
    "\n",
    "for i in range(NTHREADS):\n",
    "    # esperamos que acabe el hilo num i\n",
    "    simplethread[i].join()\n",
    "print(\"[*] all threads finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
